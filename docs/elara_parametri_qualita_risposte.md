# Parametri che Influenzano la Qualit√† delle Risposte

Questo documento raccoglie in un'unica sede tutti i parametri di configurazione che incidono direttamente sulla **qualit√† delle risposte** del motore RAG.

---

# üìö Indice
1. [Introduzione](#introduzione)
2. [Parametri del Backend AI](#parametri-del-backend-ai)
3. [Parametri di Chunking](#parametri-di-chunking)
4. [Parametri della Ricerca Vettoriale (Retrieval)](#parametri-della-ricerca-vettoriale-retrieval)
5. [Parametri del Prompt e del ChatbotService](#parametri-del-prompt-e-del-chatbotservice)
6. [Parametri di Qualit√† dei Documenti Indicizzati](#parametri-di-qualit√†-dei-documenti-indicizzati)
7. [Riepilogo finale](#riepilogo-finale)

---

# 1. Introduzione
La qualit√† della risposta generata da un motore RAG dipende dall‚Äôinterazione di pi√π componenti: il modello AI, il chunking, l‚Äôindice vettoriale, la pipeline del retrieval e la qualit√† dell‚Äôestrazione del testo.

Questo documento descrive nel dettaglio **tutti i parametri che influenzano direttamente questa qualit√†**.

---

# 2. Parametri del Backend AI

## 2.1 Modello di embedding
La scelta del modello determina la qualit√† del retrieval. Modelli con embedding pi√π ampi catturano meglio le sfumature semantiche, a scapito delle performance.

Dimensioni embedding analizzate:
- 384 ‚Üí leggero, meno preciso
- 768 ‚Üí ottimo bilanciamento
- 1024 ‚Üí alta qualit√† (es. bge‚Äëm3)
- 1536 ‚Üí qualit√† massima ma pi√π pesante

## 2.2 Modello di chat
Influisce sulla qualit√† linguistica e sul ragionamento. Modelli pi√π grandi (7B, 8B, 13B) garantiscono risposte pi√π coerenti e robuste.

## 2.3 Backend selezionato
Configurazione:
```
AI_BACKEND=ollama|openai
```
OpenAI ‚Üí qualit√† pi√π alta.  
Ollama ‚Üí locale, meno costo, pi√π latenza.

---

# 3. Parametri di Chunking
Il chunking ha impatto diretto sulla qualit√† del contesto fornito all‚ÄôAI.

## 3.1 Valori consigliati
- **Chunk min:** 400‚Äì500 caratteri
- **Chunk target:** 1200‚Äì1600 caratteri
- **Chunk max:** 1500‚Äì1800 caratteri
- **Hard limit:** 1500 caratteri
- **Overlap:** 200‚Äì300 caratteri

## 3.2 Effetti sulla qualit√†
- Chunk troppo corti ‚Üí contesto povero, embedding imprecisi
- Chunk troppo lunghi ‚Üí meno risultati pertinenti
- Chunk calibrati ‚Üí miglior recall e contesto pi√π coerente

---

# 4. Parametri della Ricerca Vettoriale (Retrieval)

## 4.1 top_k
Numero di chunk recuperati per la costruzione del contesto.

Valori consigliati:
- embedding 384 ‚Üí top_k **6**
- embedding 768 ‚Üí top_k **5**
- embedding 1024 ‚Üí top_k **4**
- embedding 1536 ‚Üí top_k **3**

## 4.2 Soglia di similarit√†
Esempio:
```
WHERE (1 - (embedding <=> :v)) > 0.55
```
Permette di escludere chunk poco rilevanti.

## 4.3 Indice vettoriale
Scelta consigliata:
### ‚úî HNSW (default raccomandato)
- Ottima qualit√† dei risultati
- Alta velocit√†
- Nessun tuning necessario

### ‚ùå IVF‚ÄëFlat solo per database enormi
- Necessita tuning (lists, probes)
- Richiede REINDEX
- Meno accurato se non calibrato

Non usare entrambi simultaneamente.

---

# 5. Parametri del Prompt e del ChatbotService

## 5.1 System prompt
Istruzione fondamentale:
```
Rispondi SOLO usando il contesto. Non inventare.
```
Riduce il rischio di hallucination.

## 5.2 Template RAG
```
# CONTEXT
{{context}}

# DOMANDA
{{question}}
```
Chiaro, robusto e aderente ai documenti.

## 5.3 Modalit√† operative
Variabili ENV:
```
APP_AI_TEST_MODE=true|false
APP_AI_OFFLINE_FALLBACK=true|false
```
Queste modalit√† influenzano il tipo di output (estratti, fallback testuale, o risposta completa generata).

---

# 6. Parametri di Qualit√† dei Documenti Indicizzati
La qualit√† del testo influisce sulla qualit√† degli embedding.

## 6.1 Normalizzazione
Il DocumentTextExtractor applica:
- rimozione whitespace multipli
- rimozione caratteri invisibili
- correzione spazi mancanti
- rimozione emoji

## 6.2 Coerenza dell‚Äôindice
Durante la reindicizzazione:
- tutti i chunk precedenti vengono rimossi per evitare dati obsoleti

Chunk puliti ‚Üí embedding di qualit√†.

---

# 7. Riepilogo Finale

| Categoria | Parametri chiave |
|----------|-------------------|
| **Backend AI** | modello embedding, modello chat, AI_BACKEND |
| **Chunking** | min, target, max, overlap, HARD_MAX_CHARS |
| **Retrieval** | top_k, soglia cosine, indice HNSW, probes IVF-FLAT |
| **Prompt** | system prompt, RAG template, modalit√† test/fallback |
| **Qualit√† documenti** | normalizzazione testo, rimozione emoji, coerenza dei chunk |

Tutti questi parametri lavorano insieme: migliorare uno solo non basta. L‚Äôottimizzazione va sempre considerata nel suo insieme.

---

