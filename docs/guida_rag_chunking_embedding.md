# Linee guida RAG: Dimensione Chunk e top_k per Diverse Dimensioni di Embedding

Questo documento riassume in forma ordinata e chiara le impostazioni di riferimento per:

- **dimensione massima del chunk di testo**
- **numero massimo di risultati (top_k)** nella query di cosine similarity
- valori di riferimento per differenti **dimensioni del vettore embedding**: 384, 768, 1024, 1536.

Include inoltre note operative utili per il setup self‚Äëhosted (16GB RAM no GPU + pgvector + Ollama).

---

# üöÄ 1. Principi generali

La qualit√† e l‚Äôefficienza del RAG dipendono soprattutto da:

- **buon chunking** (n√© troppo corto n√© troppo lungo)
- **numero appropriato di chunk restituiti** (top_k)
- **dimensione del vettore** (costo di similarity e memoria)
- **assenza di chunk "vuoti"** (problema frequente quando si spezza per caratteri fissi)

Per evitare chunk inutili ad una sola parola (es. nomi come *Malen Trast*):

- definire una **dimensione minima del chunk**
- un **overlap** del 10‚Äì20%
- merge dei paragrafi troppo brevi (< 300‚Äì400 caratteri)

---

# üìè 2. Tabella riassuntiva (valori di riferimento)

| Dimensione Vettore | Chunk max (caratteri)  | Chunk target | Chunk min | top_k |
|--------------------|------------------------|--------------|-----------|-------------------|
| **384**            | 800‚Äì1200               | ~1000        | 400       | **6**             |
| **768**            | 900‚Äì1400               | ~1200        | 400       | **5**             |
| **1024**           | 1000‚Äì1600              | ~1300‚Äì1400   | 400‚Äì500   | **4**             |
| **1536**           | 1200‚Äì1800              | ~1400‚Äì1600   | 500       | **3**             |

I valori nella colonna *target* sono quelli usati come default pratici.

---

# üß† 3. Note specifiche per ciascuna dimensione

## üîπ Embedding **384** (es. MiniLM)
- Veloce ma meno preciso.
- top_k impostato a **6**.
- Chunk non troppo lunghi: **1000 caratteri**.

## üîπ Embedding **768** (es. nomic‚Äëembed‚Äëtext)
- Punto di equilibrio per self‚Äëhosting.
- Chunk di circa **1200 caratteri**.
- top_k impostato a **5**.

## üîπ Embedding **1024** (es. mxbai‚Äëembed‚Äëlarge) attualmente usato in ELARA
- Qualit√† alta con costo computazionale maggiore.
- Chunk 1300‚Äì1400.
- top_k impostato a **4**.

## üîπ Embedding **1536** (modelli heavy stile OpenAI|Gemini)
- Costosi in pgvector su CPU.
- Per self-hosting ‚Üí top_k **3**.
- Chunk 1400‚Äì1600 caratteri.

---

# üß© 4. Parametri di chunking di riferimento per un sistema (16GB RAM senza GPU)

Con embedding **768** + modello chat 8B (valori teorici di riferimento):

- **min_chunk**: 400 caratteri
- **target_chunk**: 1200 caratteri
- **max_chunk**: 1400 caratteri
- **overlap**: 200‚Äì300 caratteri
- **top_k**: 5
- **token totali contesto**: ~1200‚Äì1500 token

Questo bilancia qualit√† del retrieval e performance, evitando timeout e surriscaldamenti.

### Configurazione attuale ELARA (bge-m3, 1024 dim)

I profili in `config/packages/rag_profiles.yaml` usano valori leggermente diversi:

| Profilo | min | max | overlap | top_k |
|---------|-----|-----|---------|-------|
| ollama-bgem3 | 380 | 1200 | 250 | 5 |
| openai-mini | 380 | 1200 | 220 | 5 |
| gemini-flash | 380 | 1200 | 220 | 5 |
| offline-test | 300 | 900 | 150 | 3 |

---
# üõ†Ô∏è 5. Considerazioni aggiuntive

### ‚úì Evitare chunk "quasi vuoti"
- Se un paragrafo √® troppo corto (<300‚Äì400 caratteri), va unito al precedente/successivo.
- Se spezzetti a misura fissa, si aggiunge un overlap.

### ‚úì Ridurre il rumore nelle query
top_k troppo alto genera contesto troppo esteso, lento e dispersivo.

### ‚úì Bilanciare i token per l‚ÄôLLM
I modelli 7B/8B in self-hosting non amano contesti da 2500+ token.

---

# ‚úÖ 6. Valori preconfigurati di riferimento (riassunto finale)

Per un setup self‚Äëhosted moderno ma non estremo (16GB RAM):

- **Embedding 768** ‚Üí configurazione pi√π usata
- **Chunk target 1200**
- **Chunk max 1400**
- **top_k = 5**
- **Overlap 200‚Äì300**

Questi valori sono adatti a documenti tecnici e qualunque tipo di conoscenza

---

# üìö 7. Best practice per pgvector

## üß© Scelta della dimensione del vettore
- Usa sempre `VECTOR(N)` come **valore fisso** nella migration.
- Anche se modelli diversi producono dimensionalit√† diverse, posso:
  - **ridurre** vettori maggiori (troncamento)
  - **zero‚Äëpadding** per vettori pi√π piccoli
- Il modo pi√π stabile √® scegliere il formato per il proprio progetto.

### Nota pratica
Per self‚Äëhosting ‚Üí **VECTOR(768)** √® una configurazione equilibrata.

---

## üöÄ Ottimizzazione database pgvector

### Indici disponibili
```sql
CREATE INDEX document_chunk_embedding_hnsw
ON document_chunk USING hnsw (embedding vector_cosine_ops);
```
- HNSW offre prestazioni elevate su dataset medi (< 500k chunk).

### Quando usare IVF-Flat
- Solo se si hanno **milioni** di chunk, dataset di grandi dimensioni.
- Richiede `REINDEX` quando si aggiungono molti dati.
- Va calibrato con `lists = 100‚Äì200`.

### Vacuum & manutenzione(IVF-Flat)
```sql
VACUUM ANALYZE document_chunk;
```
- pgvector beneficia di statistiche aggiornate.

---

# üß∞ 8. Algoritmo di chunking utilizzato(Servizio Symfony)

Di seguito un algoritmo di chunking che evita chunk troppo corti e include overlap:

```php
declare(strict_types=1);

namespace App\Service;

class ChunkingService
{
    /**
     * Limite assoluto di sicurezza sulla lunghezza di un chunk (in caratteri).
     * Serve ad evitare di mandare a Ollama input troppo lunghi, che possono
     * generare errori tipo:
     *
     *   "panic: caching disabled but unable to fit entire input in a batch"
     */
    private const HARD_MAX_CHARS = 1500;

    /**
     * Algoritmo di chunking:
     * - sistema alcuni spazi mancanti (da PDF/OCR) con fixMissingSpaces()
     * - splitta per paragrafi (2+ newline consecutivi)
     * - per ogni paragrafo crea chunk usando frasi/parole, rispettando:
     *     - $max come limite ‚Äúlogico‚Äù
     *     - HARD_MAX_CHARS come limite assoluto
     * - fa una pass veloce per evitare un ultimo chunk ridicolmente corto
     * - aggiunge overlap tra chunk (basato su parole) senza superare HARD_MAX_CHARS
     *
     * @return string[] Elenco di chunk testuali pronti per embedding / RAG
     */
    public function chunkText(
        string $text,
        int $min = 400,
        int $max = 1500,
        int $overlap = 250
    ): array {
        $text = trim($text);
        if ($text === '') {
            return [];
        }

        // Prova a correggere alcuni difetti tipici del testo estratto da PDF
        $text = $this->fixMissingSpaces($text);

        // 1) Splitta per paragrafi (due o pi√π newline consecutivi)
        $parts = preg_split("/\R{2,}/u", $text, -1, PREG_SPLIT_NO_EMPTY) ?: [];

        $baseChunks = [];
        $buffer     = '';

        foreach ($parts as $p) {
            $p = trim($p);
            if ($p === '') {
                continue;
            }

            $pLen = mb_strlen($p, 'UTF-8');

            // Se il paragrafo √® gi√† troppo lungo, lo spezzettiamo subito
            if ($pLen > $max) {
                // Flush eventuale del buffer corrente
                if ($buffer !== '') {
                    foreach ($this->splitIntoChunks($buffer, $max) as $chunk) {
                        $chunk = trim($chunk);
                        if ($chunk !== '') {
                            $baseChunks[] = $chunk;
                        }
                    }
                    $buffer = '';
                }

                foreach ($this->splitIntoChunks($p, $max) as $chunk) {
                    $chunk = trim($chunk);
                    if ($chunk !== '') {
                        $baseChunks[] = $chunk;
                    }
                }

                continue;
            }

            // Proviamo ad accumulare paragrafi nel buffer finch√© restiamo <= $max
            if ($buffer === '') {
                $buffer = $p;
                continue;
            }

            $candidate = $buffer . "\n\n" . $p;
            $len       = mb_strlen($candidate, 'UTF-8');

            if ($len <= $max) {
                // Ci sta ancora nel chunk "ideale"
                $buffer = $candidate;
            } else {
                // Il nuovo paragrafo farebbe sforare $max
                // ‚Üí chiudiamo il buffer attuale come chunk
                foreach ($this->splitIntoChunks($buffer, $max) as $chunk) {
                    $chunk = trim($chunk);
                    if ($chunk !== '') {
                        $baseChunks[] = $chunk;
                    }
                }

                // e mettiamo il paragrafo corrente in un nuovo buffer
                $buffer = $p;
            }
        }

        // Flush finale del buffer, se √® rimasto qualcosa
        if ($buffer !== '') {
            foreach ($this->splitIntoChunks($buffer, $max) as $chunk) {
                $chunk = trim($chunk);
                if ($chunk !== '') {
                    $baseChunks[] = $chunk;
                }
            }
        }

        // 2) Se l'ultimo chunk √® troppo corto rispetto al minimo, uniscilo al precedente
        $baseChunks = $this->mergeLastIfTooShort($baseChunks, $min);

        // 3) Aggiungi overlap tra chunk basato su parole, ma senza superare HARD_MAX_CHARS
        $finalChunks = $this->applyOverlap($baseChunks, $overlap);

        return $finalChunks;
    }

    /**
     * Spezza una stringa in chunk "ragionevoli" usando frasi e, se necessario, parole.
     * Garantisce che nessun chunk superi HARD_MAX_CHARS.
     *
     * @return string[]
     */
    private function splitIntoChunks(string $text, int $maxLen): array
    {
        $text = preg_replace('/\s+/u', ' ', $text);
        $text = trim($text);

        if ($text === '') {
            return [];
        }

        // Non andiamo mai oltre l'hard limit assoluto
        $maxLen = min($maxLen, self::HARD_MAX_CHARS);

        // 1) Prova a splittare per frasi
        $sentences = preg_split(
            '/(?<=[\.!?])\s+/u',
            $text,
            -1,
            PREG_SPLIT_NO_EMPTY
        ) ?: [$text];

        $chunks = [];
        $buffer = '';

        foreach ($sentences as $sentence) {
            $sentence = trim($sentence);
            if ($sentence === '') {
                continue;
            }

            $sLen = mb_strlen($sentence, 'UTF-8');

            // Se la singola frase √® gi√† pi√π lunga di $maxLen, spezza per parole
            if ($sLen > $maxLen) {
                if ($buffer !== '') {
                    $chunks[] = $buffer;
                    $buffer   = '';
                }

                foreach ($this->splitByWords($sentence, $maxLen) as $wChunk) {
                    $wChunk = trim($wChunk);
                    if ($wChunk !== '') {
                        $chunks[] = $wChunk;
                    }
                }

                continue;
            }

            // Prova ad aggiungerla al buffer
            $candidate = $buffer === '' ? $sentence : $buffer . ' ' . $sentence;
            $len       = mb_strlen($candidate, 'UTF-8');

            if ($len <= $maxLen) {
                $buffer = $candidate;
            } else {
                // Il buffer attuale va bene, chiudilo e ricomincia
                if ($buffer !== '') {
                    $chunks[] = $buffer;
                }
                $buffer = $sentence;
            }
        }

        if ($buffer !== '') {
            $chunks[] = $buffer;
        }

        // Safety finale: tutto comunque <= HARD_MAX_CHARS
        $safe = [];
        foreach ($chunks as $c) {
            $cLen = mb_strlen($c, 'UTF-8');
            if ($cLen <= self::HARD_MAX_CHARS) {
                $safe[] = $c;
                continue;
            }

            foreach ($this->splitByWords($c, self::HARD_MAX_CHARS) as $wChunk) {
                $wChunk = trim($wChunk);
                if ($wChunk !== '') {
                    $safe[] = $wChunk;
                }
            }
        }

        return $safe;
    }

    /**
     * Split "brutale" per parole, garantendo chunk <= $maxLen.
     *
     * @return string[]
     */
    private function splitByWords(string $text, int $maxLen): array
    {
        $words = preg_split('/\s+/u', $text, -1, PREG_SPLIT_NO_EMPTY) ?: [];

        $chunks = [];
        $buffer = '';

        foreach ($words as $word) {
            $word = trim($word);
            if ($word === '') {
                continue;
            }

            $candidate = $buffer === '' ? $word : $buffer . ' ' . $word;
            $len       = mb_strlen($candidate, 'UTF-8');

            if ($len <= $maxLen) {
                $buffer = $candidate;
                continue;
            }

            if ($buffer !== '') {
                $chunks[] = $buffer;
            }

            // Se la singola parola supera il limite, taglio brutale
            if (mb_strlen($word, 'UTF-8') > $maxLen) {
                $chunks[] = mb_substr($word, 0, $maxLen, 'UTF-8');
                $buffer   = '';
            } else {
                $buffer = $word;
            }
        }

        if ($buffer !== '') {
            $chunks[] = $buffer;
        }

        return $chunks;
    }

    /**
     * Unisce l‚Äôultimo chunk al precedente se √® molto pi√π corto del minimo desiderato.
     */
    private function mergeLastIfTooShort(array $chunks, int $min): array
    {
        $count = count($chunks);
        if ($count < 2) {
            return $chunks;
        }

        $last     = $chunks[$count - 1];
        $lastLen  = mb_strlen($last, 'UTF-8');

        if ($lastLen >= $min) {
            return $chunks;
        }

        $prev     = $chunks[$count - 2];
        $merged   = $prev . "\n\n" . $last;
        $mergedLen = mb_strlen($merged, 'UTF-8');

        if ($mergedLen <= self::HARD_MAX_CHARS) {
            $chunks[$count - 2] = $merged;
            array_pop($chunks);
        }

        return $chunks;
    }

    /**
     * Applica overlap tra chunk, usando le *ultime parole* del chunk precedente.
     * L'overlap √® espresso in "caratteri obiettivo", non in numero di parole.
     * Si assicura di non superare HARD_MAX_CHARS.
     *
     * @param string[] $chunks
     * @return string[]
     */
    private function applyOverlap(array $chunks, int $overlapChars): array
    {
        if ($overlapChars <= 0 || count($chunks) === 0) {
            return $chunks;
        }

        $final = [];
        $count = count($chunks);

        for ($i = 0; $i < $count; $i++) {
            $chunk = trim($chunks[$i]);
            if ($chunk === '') {
                continue;
            }

            // Nessun overlap per il primo chunk
            if ($i === 0) {
                $final[] = $chunk;
                continue;
            }

            $prev = $chunks[$i - 1];

            // Quanto spazio abbiamo per il prefisso, restando entro HARD_MAX_CHARS?
            $chunkLen  = mb_strlen($chunk, 'UTF-8');
            $available = self::HARD_MAX_CHARS - $chunkLen - 2; // -2 per "\n\n"

            if ($available <= 0) {
                // Non c'√® spazio per overlap, teniamo solo il chunk
                $final[] = $chunk;
                continue;
            }

            // L'overlap reale √® il min tra richiesto e disponibile
            $effectiveOverlap = min($overlapChars, $available);

            $prefix = $this->buildWordOverlap($prev, $effectiveOverlap);
            if ($prefix === '') {
                $final[] = $chunk;
                continue;
            }

            $candidate = $prefix . "\n\n" . $chunk;

            // Safety extra, nel caso l'overlap sia ancora troppo grande
            if (mb_strlen($candidate, 'UTF-8') > self::HARD_MAX_CHARS) {
                $final[] = $chunk;
                continue;
            }

            $final[] = $candidate;
        }

        return $final;
    }

    /**
     * Costruisce un overlap basato su parole (non su caratteri).
     * Prende le ultime parole del chunk precedente finch√© non
     * supera approssimativamente overlapChars caratteri.
     */
    private function buildWordOverlap(string $prev, int $overlapChars): string
    {
        $prev = trim($prev);
        if ($overlapChars <= 0 || $prev === '') {
            return '';
        }

        $words = preg_split('/\s+/u', $prev, -1, PREG_SPLIT_NO_EMPTY);
        if (!$words || count($words) === 0) {
            return '';
        }

        $selected = [];
        $totalLen = 0;

        // Parti dalla fine e risali
        for ($i = count($words) - 1; $i >= 0; $i--) {
            $w = $words[$i];

            $wLen = mb_strlen($w, 'UTF-8');

            // +1 per lo spazio che si aggiunge tra le parole
            if ($totalLen > 0) {
                $wLen += 1;
            }

            if ($totalLen + $wLen > $overlapChars && !empty($selected)) {
                break;
            }

            array_unshift($selected, $w);
            $totalLen += $wLen;

            if ($totalLen >= $overlapChars) {
                break;
            }
        }

        return implode(' ', $selected);
    }

    /**
     * Corregge alcuni casi tipici di "spazi mancanti" dovuti all'estrazione da PDF:
     *  1) Nessuno spazio dopo . ! ? ; :
     *  2) ALL-CAPS subito seguite da parola capitalizzata (MOTIVAZIONIRuolo)
     *  3) minuscola seguita da maiuscola senza spazio (standard.Origini)
     */
    public function fixMissingSpaces(string $text): string
    {
        // 1) Spazio dopo ., !, ?, ;, : se NON c'√® gi√† uno spazio
        // es: "dominanti:Carisma" -> "dominanti: Carisma"
        $text = preg_replace(
            '/([\.!?;:])([^\s])/u',
            '$1 $2',
            $text
        );

        // 2) Spazio tra parola ALL-CAPS e parola Capitalized attaccate
        // es: "MOTIVAZIONIRuolo" -> "MOTIVAZIONI Ruolo"
        //     "PSICOLOGICOEt√†"   -> "PSICOLOGICO Et√†"
        $text = preg_replace(
            '/\b([A-Z√Ä-√ñ√ò-√ù]{2,})([A-Z√Ä-√ñ√ò-√ù][a-z√†-√∂√∏-√ø]+)/u',
            '$1 $2',
            $text
        );

        // 3) Spazio tra minuscola e maiuscola attaccate (caso generico)
        // es: "standard.Origini" -> "standard. Origini"
        $text = preg_replace(
            '/([\p{Ll}])([\p{Lu}])/u',
            '$1 $2',
            $text
        );

        return $text;
    }
}

```

### Benefici di questo metodo
- Evita chunk ‚Äúcadaveri‚Äù (solo titoletti o nomi)
- Mantiene la coerenza semantica
- Inserisce un overlap che aumenta la recall
- Produce chunk di lunghezza prevedibile

---

# üîé 9. Esempi di query SQL pgvector ottimizzate

## Cosine similarity standard
```sql
SELECT id, path, text,
       1 - (embedding <=> :query_vec) AS score
FROM document_chunk
ORDER BY embedding <=> :query_vec
LIMIT 5;
```

## Con filtraggio per documento
```sql
SELECT id, text
FROM document_chunk
WHERE path = :doc
ORDER BY embedding <=> :q
LIMIT :k;
```

## Con soglia minima di score
```sql
SELECT *, 1 - (embedding <=> :v) AS score
FROM document_chunk
WHERE (1 - (embedding <=> :v)) > 0.55
ORDER BY embedding <=> :v
LIMIT 5;
```

### Nota
- Le soglie dipendono dal modello: per embedding 768 di qualit√†, **0.55‚Äì0.60** √® un range comune.

---

# üß† 10. Prompt template per RAG

```text
Sei un assistente e DEVI rispondere esclusivamente usando il contesto sotto.
Se la risposta non √® presente nel contesto, di' che non √® disponibile.

# CONTEX
{{context}}

# DOMANDA
{{question}}

Rispondi in modo chiaro e sintetico nella lingua dell'utente.
```

### Perch√© funziona bene
- Evita hallucination
- Costringe l‚ÄôLLM a usare i chunk
- Funziona bene con modelli 7B/8B self‚Äëhosted

---

# üóÑÔ∏è 11. Uso combinato di **IVF-FLAT + HNSW**

## Panoramica
Per un sistema RAG **self‚Äëhosted**, con **16 GB di RAM** e dataset di dimensioni medio‚Äëpiccole (documentazione, lore, manuali), usare entrambi gli indici sulla stessa colonna di embedding non aggiunge benefici misurabili.

In questo scenario si impiega un solo indice, tipicamente **HNSW**.

---

# üß© 11.1. Differenze tra IVF-FLAT e HNSW

## üîπ HNSW
**Usato per:** dataset piccoli/medi (fino a milioni moderati), contesti RAG.

**Pro:**
- Ottima qualit√† dei risultati (alta recall)
- Query veloci
- Zero tuning complesso

**Contro:**
- Indice un po‚Äô pi√π pesante
- Pi√π RAM rispetto a un IVFFlat minimale

---

## üîπ IVF-FLAT
**Impiegato su:** dataset **molto grandi** (milioni di embedding).

**Pro:**
- Scalabile su enormi volumi
- Query pi√π leggere se configurato bene

**Contro:**
- Recall pi√π bassa se `lists`/`probes` non sono calibrati
- Necessita tuning
- Richiede "REINDEX" dopo grandi batch di insert
- Su knowledge base medio-piccole, HNSW offre risultati pi√π stabili con meno configurazione.

---

# üß† 11.2. Perch√© NON usarli insieme

Avere **due indici** (HNSW + IVF-FLAT) sulla stessa colonna comporta:

### ‚ùó Problemi
- **Pi√π spazio su disco**
- **Planner meno prevedibile** (Postgres pu√≤ scegliere l'indice peggiore)
- **Build pi√π lente**
- **Manutenzione raddoppiata**
- **Recall instabile** se IVF-FLAT non √® configurato bene

### üëç In questo contesto
- Dataset non enorme
- Self‚Äëhosting 16GB RAM senza GPU
- Performance gi√† buone con HNSW
- Nessuna necessit√† di clusterizzazione (IV-FFLAT)

üëâ **Conclusione:** l'uso simultaneo non √® previsto in questo contesto e aumenta costi e complessit√†.

---

# üü¢ 11.3. Scelte operative

### Usa **solo HNSW**:
```sql
CREATE INDEX document_chunk_embedding_hnsw
ON document_chunk
USING hnsw (embedding vector_cosine_ops);
```

### Quando valutare IVF-FLAT?
Solo se:
- superi **1‚Äì2 milioni di chunk**
- e hai problemi di latenza sulla similarity
- e sei disposto a fare tuning di:
  - `lists`
  - `probes`
  - strategie di REINDEX

Negli altri casi ‚Üí **HNSW** mantiene configurazione semplice e stabile.

### TL;DR finale
- **HNSW** = default usato sulla maggior parte delle knowledge base.
- **IVF-FLAT** = strumento per dataset enormi dove il tuning √® accettabile.
- **Uno alla volta**: duplicare gli indici porta solo costi.

---

# üß™ 11.4. Come verificare che Postgres sta davvero usando HNSW

```sql
EXPLAIN ANALYZE
SELECT id, text
FROM document_chunk
ORDER BY embedding <=> :q
LIMIT 5;
```

Si dovrebbe vedere qualcosa come:
```
Index Scan using document_chunk_embedding_hnsw on document_chunk
```
Se invece si vede "Seq Scan" ‚Üí manca l'indice o Postgres non lo ritiene conveniente.
